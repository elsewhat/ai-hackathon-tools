/*
 * Azure OpenAI Service API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2023-09-01-preview
 * Generated by: https://github.com/openapitools/openapi-generator.git
 */


using System;
using System.Collections.Generic;
using System.Collections.ObjectModel;
using System.Linq;
using System.Net;
using System.Net.Mime;
using AzureOpenAI.Client;
using AzureOpenAI.Client.Auth;
using AzureOpenAI.Model;

namespace AzureOpenAI.Api
{

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public interface IDefaultApiSync : IApiAccessor
    {
        #region Synchronous Operations
        /// <summary>
        /// Creates a completion for the chat message
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>CreateChatCompletionResponse</returns>
        CreateChatCompletionResponse ChatCompletionsCreate(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0);

        /// <summary>
        /// Creates a completion for the chat message
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of CreateChatCompletionResponse</returns>
        ApiResponse<CreateChatCompletionResponse> ChatCompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0);
        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model.
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>CompletionsCreate200Response</returns>
        CompletionsCreate200Response CompletionsCreate(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0);

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of CompletionsCreate200Response</returns>
        ApiResponse<CompletionsCreate200Response> CompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0);
        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>EmbeddingsCreate200Response</returns>
        EmbeddingsCreate200Response EmbeddingsCreate(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0);

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of EmbeddingsCreate200Response</returns>
        ApiResponse<EmbeddingsCreate200Response> EmbeddingsCreateWithHttpInfo(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0);
        /// <summary>
        /// Using extensions to creates a completion for the chat messages.
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ExtensionsChatCompletionsResponse</returns>
        ExtensionsChatCompletionsResponse ExtensionsChatCompletionsCreate(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0);

        /// <summary>
        /// Using extensions to creates a completion for the chat messages.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of ExtensionsChatCompletionsResponse</returns>
        ApiResponse<ExtensionsChatCompletionsResponse> ExtensionsChatCompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0);
        /// <summary>
        /// Transcribes audio into the input language.
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>TranscriptionsCreate200Response</returns>
        TranscriptionsCreate200Response TranscriptionsCreate(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0);

        /// <summary>
        /// Transcribes audio into the input language.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of TranscriptionsCreate200Response</returns>
        ApiResponse<TranscriptionsCreate200Response> TranscriptionsCreateWithHttpInfo(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0);
        /// <summary>
        /// Transcribes and translates input audio into English text.
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>TranscriptionsCreate200Response</returns>
        TranscriptionsCreate200Response TranslationsCreate(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0);

        /// <summary>
        /// Transcribes and translates input audio into English text.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of TranscriptionsCreate200Response</returns>
        ApiResponse<TranscriptionsCreate200Response> TranslationsCreateWithHttpInfo(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0);
        #endregion Synchronous Operations
    }

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public interface IDefaultApiAsync : IApiAccessor
    {
        #region Asynchronous Operations
        /// <summary>
        /// Creates a completion for the chat message
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of CreateChatCompletionResponse</returns>
        System.Threading.Tasks.Task<CreateChatCompletionResponse> ChatCompletionsCreateAsync(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Creates a completion for the chat message
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (CreateChatCompletionResponse)</returns>
        System.Threading.Tasks.Task<ApiResponse<CreateChatCompletionResponse>> ChatCompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of CompletionsCreate200Response</returns>
        System.Threading.Tasks.Task<CompletionsCreate200Response> CompletionsCreateAsync(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (CompletionsCreate200Response)</returns>
        System.Threading.Tasks.Task<ApiResponse<CompletionsCreate200Response>> CompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of EmbeddingsCreate200Response</returns>
        System.Threading.Tasks.Task<EmbeddingsCreate200Response> EmbeddingsCreateAsync(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (EmbeddingsCreate200Response)</returns>
        System.Threading.Tasks.Task<ApiResponse<EmbeddingsCreate200Response>> EmbeddingsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        /// <summary>
        /// Using extensions to creates a completion for the chat messages.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ExtensionsChatCompletionsResponse</returns>
        System.Threading.Tasks.Task<ExtensionsChatCompletionsResponse> ExtensionsChatCompletionsCreateAsync(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Using extensions to creates a completion for the chat messages.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (ExtensionsChatCompletionsResponse)</returns>
        System.Threading.Tasks.Task<ApiResponse<ExtensionsChatCompletionsResponse>> ExtensionsChatCompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        /// <summary>
        /// Transcribes audio into the input language.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of TranscriptionsCreate200Response</returns>
        System.Threading.Tasks.Task<TranscriptionsCreate200Response> TranscriptionsCreateAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Transcribes audio into the input language.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (TranscriptionsCreate200Response)</returns>
        System.Threading.Tasks.Task<ApiResponse<TranscriptionsCreate200Response>> TranscriptionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        /// <summary>
        /// Transcribes and translates input audio into English text.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of TranscriptionsCreate200Response</returns>
        System.Threading.Tasks.Task<TranscriptionsCreate200Response> TranslationsCreateAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));

        /// <summary>
        /// Transcribes and translates input audio into English text.
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (TranscriptionsCreate200Response)</returns>
        System.Threading.Tasks.Task<ApiResponse<TranscriptionsCreate200Response>> TranslationsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken));
        #endregion Asynchronous Operations
    }

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public interface IDefaultApi : IDefaultApiSync, IDefaultApiAsync
    {

    }

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public partial class DefaultApi : IDefaultApi
    {
        private AzureOpenAI.Client.ExceptionFactory _exceptionFactory = (name, response) => null;

        /// <summary>
        /// Initializes a new instance of the <see cref="DefaultApi"/> class.
        /// </summary>
        /// <returns></returns>
        public DefaultApi() : this((string)null)
        {
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="DefaultApi"/> class.
        /// </summary>
        /// <returns></returns>
        public DefaultApi(string basePath)
        {
            this.Configuration = AzureOpenAI.Client.Configuration.MergeConfigurations(
                AzureOpenAI.Client.GlobalConfiguration.Instance,
                new AzureOpenAI.Client.Configuration { BasePath = basePath }
            );
            this.Client = new AzureOpenAI.Client.ApiClient(this.Configuration.BasePath);
            this.AsynchronousClient = new AzureOpenAI.Client.ApiClient(this.Configuration.BasePath);
            this.ExceptionFactory = AzureOpenAI.Client.Configuration.DefaultExceptionFactory;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="DefaultApi"/> class
        /// using Configuration object
        /// </summary>
        /// <param name="configuration">An instance of Configuration</param>
        /// <returns></returns>
        public DefaultApi(AzureOpenAI.Client.Configuration configuration)
        {
            if (configuration == null) throw new ArgumentNullException("configuration");

            this.Configuration = AzureOpenAI.Client.Configuration.MergeConfigurations(
                AzureOpenAI.Client.GlobalConfiguration.Instance,
                configuration
            );
            this.Client = new AzureOpenAI.Client.ApiClient(this.Configuration.BasePath);
            this.AsynchronousClient = new AzureOpenAI.Client.ApiClient(this.Configuration.BasePath);
            ExceptionFactory = AzureOpenAI.Client.Configuration.DefaultExceptionFactory;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="DefaultApi"/> class
        /// using a Configuration object and client instance.
        /// </summary>
        /// <param name="client">The client interface for synchronous API access.</param>
        /// <param name="asyncClient">The client interface for asynchronous API access.</param>
        /// <param name="configuration">The configuration object.</param>
        public DefaultApi(AzureOpenAI.Client.ISynchronousClient client, AzureOpenAI.Client.IAsynchronousClient asyncClient, AzureOpenAI.Client.IReadableConfiguration configuration)
        {
            if (client == null) throw new ArgumentNullException("client");
            if (asyncClient == null) throw new ArgumentNullException("asyncClient");
            if (configuration == null) throw new ArgumentNullException("configuration");

            this.Client = client;
            this.AsynchronousClient = asyncClient;
            this.Configuration = configuration;
            this.ExceptionFactory = AzureOpenAI.Client.Configuration.DefaultExceptionFactory;
        }

        /// <summary>
        /// The client for accessing this underlying API asynchronously.
        /// </summary>
        public AzureOpenAI.Client.IAsynchronousClient AsynchronousClient { get; set; }

        /// <summary>
        /// The client for accessing this underlying API synchronously.
        /// </summary>
        public AzureOpenAI.Client.ISynchronousClient Client { get; set; }

        /// <summary>
        /// Gets the base path of the API client.
        /// </summary>
        /// <value>The base path</value>
        public string GetBasePath()
        {
            return this.Configuration.BasePath;
        }

        /// <summary>
        /// Gets or sets the configuration object
        /// </summary>
        /// <value>An instance of the Configuration</value>
        public AzureOpenAI.Client.IReadableConfiguration Configuration { get; set; }

        /// <summary>
        /// Provides a factory method hook for the creation of exceptions.
        /// </summary>
        public AzureOpenAI.Client.ExceptionFactory ExceptionFactory
        {
            get
            {
                if (_exceptionFactory != null && _exceptionFactory.GetInvocationList().Length > 1)
                {
                    throw new InvalidOperationException("Multicast delegate for ExceptionFactory is unsupported.");
                }
                return _exceptionFactory;
            }
            set { _exceptionFactory = value; }
        }

        /// <summary>
        /// Creates a completion for the chat message 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>CreateChatCompletionResponse</returns>
        public CreateChatCompletionResponse ChatCompletionsCreate(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<CreateChatCompletionResponse> localVarResponse = ChatCompletionsCreateWithHttpInfo(deploymentId, apiVersion, createChatCompletionRequest);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Creates a completion for the chat message 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of CreateChatCompletionResponse</returns>
        public AzureOpenAI.Client.ApiResponse<CreateChatCompletionResponse> ChatCompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->ChatCompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->ChatCompletionsCreate");
            }

            // verify the required parameter 'createChatCompletionRequest' is set
            if (createChatCompletionRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'createChatCompletionRequest' when calling DefaultApi->ChatCompletionsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = createChatCompletionRequest;

            localVarRequestOptions.Operation = "DefaultApi.ChatCompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<CreateChatCompletionResponse>("/deployments/{deployment-id}/chat/completions", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("ChatCompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Creates a completion for the chat message 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of CreateChatCompletionResponse</returns>
        public async System.Threading.Tasks.Task<CreateChatCompletionResponse> ChatCompletionsCreateAsync(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<CreateChatCompletionResponse> localVarResponse = await ChatCompletionsCreateWithHttpInfoAsync(deploymentId, apiVersion, createChatCompletionRequest, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Creates a completion for the chat message 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="createChatCompletionRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (CreateChatCompletionResponse)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<CreateChatCompletionResponse>> ChatCompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, CreateChatCompletionRequest createChatCompletionRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->ChatCompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->ChatCompletionsCreate");
            }

            // verify the required parameter 'createChatCompletionRequest' is set
            if (createChatCompletionRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'createChatCompletionRequest' when calling DefaultApi->ChatCompletionsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = createChatCompletionRequest;

            localVarRequestOptions.Operation = "DefaultApi.ChatCompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<CreateChatCompletionResponse>("/deployments/{deployment-id}/chat/completions", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("ChatCompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>CompletionsCreate200Response</returns>
        public CompletionsCreate200Response CompletionsCreate(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<CompletionsCreate200Response> localVarResponse = CompletionsCreateWithHttpInfo(deploymentId, apiVersion, completionsCreateRequest);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of CompletionsCreate200Response</returns>
        public AzureOpenAI.Client.ApiResponse<CompletionsCreate200Response> CompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->CompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->CompletionsCreate");
            }

            // verify the required parameter 'completionsCreateRequest' is set
            if (completionsCreateRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'completionsCreateRequest' when calling DefaultApi->CompletionsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = completionsCreateRequest;

            localVarRequestOptions.Operation = "DefaultApi.CompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<CompletionsCreate200Response>("/deployments/{deployment-id}/completions", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("CompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of CompletionsCreate200Response</returns>
        public async System.Threading.Tasks.Task<CompletionsCreate200Response> CompletionsCreateAsync(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<CompletionsCreate200Response> localVarResponse = await CompletionsCreateWithHttpInfoAsync(deploymentId, apiVersion, completionsCreateRequest, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Creates a completion for the provided prompt, parameters and chosen model. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="completionsCreateRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (CompletionsCreate200Response)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<CompletionsCreate200Response>> CompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, CompletionsCreateRequest completionsCreateRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->CompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->CompletionsCreate");
            }

            // verify the required parameter 'completionsCreateRequest' is set
            if (completionsCreateRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'completionsCreateRequest' when calling DefaultApi->CompletionsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = completionsCreateRequest;

            localVarRequestOptions.Operation = "DefaultApi.CompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<CompletionsCreate200Response>("/deployments/{deployment-id}/completions", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("CompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>EmbeddingsCreate200Response</returns>
        public EmbeddingsCreate200Response EmbeddingsCreate(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<EmbeddingsCreate200Response> localVarResponse = EmbeddingsCreateWithHttpInfo(deploymentId, apiVersion, requestBody);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of EmbeddingsCreate200Response</returns>
        public AzureOpenAI.Client.ApiResponse<EmbeddingsCreate200Response> EmbeddingsCreateWithHttpInfo(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->EmbeddingsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->EmbeddingsCreate");
            }

            // verify the required parameter 'requestBody' is set
            if (requestBody == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'requestBody' when calling DefaultApi->EmbeddingsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = requestBody;

            localVarRequestOptions.Operation = "DefaultApi.EmbeddingsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<EmbeddingsCreate200Response>("/deployments/{deployment-id}/embeddings", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("EmbeddingsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of EmbeddingsCreate200Response</returns>
        public async System.Threading.Tasks.Task<EmbeddingsCreate200Response> EmbeddingsCreateAsync(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<EmbeddingsCreate200Response> localVarResponse = await EmbeddingsCreateWithHttpInfoAsync(deploymentId, apiVersion, requestBody, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId">The deployment id of the model which was deployed.</param>
        /// <param name="apiVersion"></param>
        /// <param name="requestBody"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (EmbeddingsCreate200Response)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<EmbeddingsCreate200Response>> EmbeddingsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, Dictionary<string, Object> requestBody, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->EmbeddingsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->EmbeddingsCreate");
            }

            // verify the required parameter 'requestBody' is set
            if (requestBody == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'requestBody' when calling DefaultApi->EmbeddingsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = requestBody;

            localVarRequestOptions.Operation = "DefaultApi.EmbeddingsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<EmbeddingsCreate200Response>("/deployments/{deployment-id}/embeddings", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("EmbeddingsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Using extensions to creates a completion for the chat messages. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ExtensionsChatCompletionsResponse</returns>
        public ExtensionsChatCompletionsResponse ExtensionsChatCompletionsCreate(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<ExtensionsChatCompletionsResponse> localVarResponse = ExtensionsChatCompletionsCreateWithHttpInfo(deploymentId, apiVersion, extensionsChatCompletionsRequest);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Using extensions to creates a completion for the chat messages. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of ExtensionsChatCompletionsResponse</returns>
        public AzureOpenAI.Client.ApiResponse<ExtensionsChatCompletionsResponse> ExtensionsChatCompletionsCreateWithHttpInfo(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }

            // verify the required parameter 'extensionsChatCompletionsRequest' is set
            if (extensionsChatCompletionsRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'extensionsChatCompletionsRequest' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = extensionsChatCompletionsRequest;

            localVarRequestOptions.Operation = "DefaultApi.ExtensionsChatCompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<ExtensionsChatCompletionsResponse>("/deployments/{deployment-id}/extensions/chat/completions", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("ExtensionsChatCompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Using extensions to creates a completion for the chat messages. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ExtensionsChatCompletionsResponse</returns>
        public async System.Threading.Tasks.Task<ExtensionsChatCompletionsResponse> ExtensionsChatCompletionsCreateAsync(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<ExtensionsChatCompletionsResponse> localVarResponse = await ExtensionsChatCompletionsCreateWithHttpInfoAsync(deploymentId, apiVersion, extensionsChatCompletionsRequest, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Using extensions to creates a completion for the chat messages. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion"></param>
        /// <param name="extensionsChatCompletionsRequest"></param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (ExtensionsChatCompletionsResponse)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<ExtensionsChatCompletionsResponse>> ExtensionsChatCompletionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, ExtensionsChatCompletionsRequest extensionsChatCompletionsRequest, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }

            // verify the required parameter 'extensionsChatCompletionsRequest' is set
            if (extensionsChatCompletionsRequest == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'extensionsChatCompletionsRequest' when calling DefaultApi->ExtensionsChatCompletionsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "application/json"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.Data = extensionsChatCompletionsRequest;

            localVarRequestOptions.Operation = "DefaultApi.ExtensionsChatCompletionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<ExtensionsChatCompletionsResponse>("/deployments/{deployment-id}/extensions/chat/completions", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("ExtensionsChatCompletionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Transcribes audio into the input language. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>TranscriptionsCreate200Response</returns>
        public TranscriptionsCreate200Response TranscriptionsCreate(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> localVarResponse = TranscriptionsCreateWithHttpInfo(deploymentId, apiVersion, file, prompt, responseFormat, temperature, language);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Transcribes audio into the input language. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of TranscriptionsCreate200Response</returns>
        public AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> TranscriptionsCreateWithHttpInfo(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->TranscriptionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->TranscriptionsCreate");
            }

            // verify the required parameter 'file' is set
            if (file == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'file' when calling DefaultApi->TranscriptionsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "multipart/form-data"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json",
                "text/plain"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.FileParameters.Add("file", file);
            if (prompt != null)
            {
                localVarRequestOptions.FormParameters.Add("prompt", AzureOpenAI.Client.ClientUtils.ParameterToString(prompt)); // form parameter
            }
            if (responseFormat != null)
            {
                localVarRequestOptions.FormParameters.Add("response_format", AzureOpenAI.Client.ClientUtils.ParameterToString(responseFormat)); // form parameter
            }
            if (temperature != null)
            {
                localVarRequestOptions.FormParameters.Add("temperature", AzureOpenAI.Client.ClientUtils.ParameterToString(temperature)); // form parameter
            }
            if (language != null)
            {
                localVarRequestOptions.FormParameters.Add("language", AzureOpenAI.Client.ClientUtils.ParameterToString(language)); // form parameter
            }

            localVarRequestOptions.Operation = "DefaultApi.TranscriptionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<TranscriptionsCreate200Response>("/deployments/{deployment-id}/audio/transcriptions", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("TranscriptionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Transcribes audio into the input language. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of TranscriptionsCreate200Response</returns>
        public async System.Threading.Tasks.Task<TranscriptionsCreate200Response> TranscriptionsCreateAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> localVarResponse = await TranscriptionsCreateWithHttpInfoAsync(deploymentId, apiVersion, file, prompt, responseFormat, temperature, language, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Transcribes audio into the input language. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file object to transcribe.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="language">The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. (optional)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (TranscriptionsCreate200Response)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response>> TranscriptionsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), string? language = default(string?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->TranscriptionsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->TranscriptionsCreate");
            }

            // verify the required parameter 'file' is set
            if (file == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'file' when calling DefaultApi->TranscriptionsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "multipart/form-data"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json",
                "text/plain"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.FileParameters.Add("file", file);
            if (prompt != null)
            {
                localVarRequestOptions.FormParameters.Add("prompt", AzureOpenAI.Client.ClientUtils.ParameterToString(prompt)); // form parameter
            }
            if (responseFormat != null)
            {
                localVarRequestOptions.FormParameters.Add("response_format", AzureOpenAI.Client.ClientUtils.ParameterToString(responseFormat)); // form parameter
            }
            if (temperature != null)
            {
                localVarRequestOptions.FormParameters.Add("temperature", AzureOpenAI.Client.ClientUtils.ParameterToString(temperature)); // form parameter
            }
            if (language != null)
            {
                localVarRequestOptions.FormParameters.Add("language", AzureOpenAI.Client.ClientUtils.ParameterToString(language)); // form parameter
            }

            localVarRequestOptions.Operation = "DefaultApi.TranscriptionsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<TranscriptionsCreate200Response>("/deployments/{deployment-id}/audio/transcriptions", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("TranscriptionsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Transcribes and translates input audio into English text. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>TranscriptionsCreate200Response</returns>
        public TranscriptionsCreate200Response TranslationsCreate(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0)
        {
            AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> localVarResponse = TranslationsCreateWithHttpInfo(deploymentId, apiVersion, file, prompt, responseFormat, temperature);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Transcribes and translates input audio into English text. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <returns>ApiResponse of TranscriptionsCreate200Response</returns>
        public AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> TranslationsCreateWithHttpInfo(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0)
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->TranslationsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->TranslationsCreate");
            }

            // verify the required parameter 'file' is set
            if (file == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'file' when calling DefaultApi->TranslationsCreate");
            }

            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "multipart/form-data"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json",
                "text/plain"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.FileParameters.Add("file", file);
            if (prompt != null)
            {
                localVarRequestOptions.FormParameters.Add("prompt", AzureOpenAI.Client.ClientUtils.ParameterToString(prompt)); // form parameter
            }
            if (responseFormat != null)
            {
                localVarRequestOptions.FormParameters.Add("response_format", AzureOpenAI.Client.ClientUtils.ParameterToString(responseFormat)); // form parameter
            }
            if (temperature != null)
            {
                localVarRequestOptions.FormParameters.Add("temperature", AzureOpenAI.Client.ClientUtils.ParameterToString(temperature)); // form parameter
            }

            localVarRequestOptions.Operation = "DefaultApi.TranslationsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = this.Client.Post<TranscriptionsCreate200Response>("/deployments/{deployment-id}/audio/translations", localVarRequestOptions, this.Configuration);
            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("TranslationsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

        /// <summary>
        /// Transcribes and translates input audio into English text. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of TranscriptionsCreate200Response</returns>
        public async System.Threading.Tasks.Task<TranscriptionsCreate200Response> TranslationsCreateAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response> localVarResponse = await TranslationsCreateWithHttpInfoAsync(deploymentId, apiVersion, file, prompt, responseFormat, temperature, operationIndex, cancellationToken).ConfigureAwait(false);
            return localVarResponse.Data;
        }

        /// <summary>
        /// Transcribes and translates input audio into English text. 
        /// </summary>
        /// <exception cref="AzureOpenAI.Client.ApiException">Thrown when fails to make API call</exception>
        /// <param name="deploymentId"></param>
        /// <param name="apiVersion">Api version.</param>
        /// <param name="file">The audio file to translate.</param>
        /// <param name="prompt">An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should be in English. (optional)</param>
        /// <param name="responseFormat"> (optional)</param>
        /// <param name="temperature">The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. (optional, default to 0M)</param>
        /// <param name="operationIndex">Index associated with the operation.</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns>Task of ApiResponse (TranscriptionsCreate200Response)</returns>
        public async System.Threading.Tasks.Task<AzureOpenAI.Client.ApiResponse<TranscriptionsCreate200Response>> TranslationsCreateWithHttpInfoAsync(string deploymentId, string apiVersion, System.IO.Stream file, string? prompt = default(string?), ResponseFormat? responseFormat = default(ResponseFormat?), decimal? temperature = default(decimal?), int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
        {
            // verify the required parameter 'deploymentId' is set
            if (deploymentId == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'deploymentId' when calling DefaultApi->TranslationsCreate");
            }

            // verify the required parameter 'apiVersion' is set
            if (apiVersion == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'apiVersion' when calling DefaultApi->TranslationsCreate");
            }

            // verify the required parameter 'file' is set
            if (file == null)
            {
                throw new AzureOpenAI.Client.ApiException(400, "Missing required parameter 'file' when calling DefaultApi->TranslationsCreate");
            }


            AzureOpenAI.Client.RequestOptions localVarRequestOptions = new AzureOpenAI.Client.RequestOptions();

            string[] _contentTypes = new string[] {
                "multipart/form-data"
            };

            // to determine the Accept header
            string[] _accepts = new string[] {
                "application/json",
                "text/plain"
            };

            var localVarContentType = AzureOpenAI.Client.ClientUtils.SelectHeaderContentType(_contentTypes);
            if (localVarContentType != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Content-Type", localVarContentType);
            }

            var localVarAccept = AzureOpenAI.Client.ClientUtils.SelectHeaderAccept(_accepts);
            if (localVarAccept != null)
            {
                localVarRequestOptions.HeaderParameters.Add("Accept", localVarAccept);
            }

            localVarRequestOptions.PathParameters.Add("deployment-id", AzureOpenAI.Client.ClientUtils.ParameterToString(deploymentId)); // path parameter
            localVarRequestOptions.QueryParameters.Add(AzureOpenAI.Client.ClientUtils.ParameterToMultiMap("", "api-version", apiVersion));
            localVarRequestOptions.FileParameters.Add("file", file);
            if (prompt != null)
            {
                localVarRequestOptions.FormParameters.Add("prompt", AzureOpenAI.Client.ClientUtils.ParameterToString(prompt)); // form parameter
            }
            if (responseFormat != null)
            {
                localVarRequestOptions.FormParameters.Add("response_format", AzureOpenAI.Client.ClientUtils.ParameterToString(responseFormat)); // form parameter
            }
            if (temperature != null)
            {
                localVarRequestOptions.FormParameters.Add("temperature", AzureOpenAI.Client.ClientUtils.ParameterToString(temperature)); // form parameter
            }

            localVarRequestOptions.Operation = "DefaultApi.TranslationsCreate";
            localVarRequestOptions.OperationIndex = operationIndex;

            // authentication (apiKey) required
            if (!string.IsNullOrEmpty(this.Configuration.GetApiKeyWithPrefix("api-key")))
            {
                localVarRequestOptions.HeaderParameters.Add("api-key", this.Configuration.GetApiKeyWithPrefix("api-key"));
            }
            // authentication (bearer) required
            // oauth required
            if (!localVarRequestOptions.HeaderParameters.ContainsKey("Authorization"))
            {
                if (!string.IsNullOrEmpty(this.Configuration.AccessToken))
                {
                    localVarRequestOptions.HeaderParameters.Add("Authorization", "Bearer " + this.Configuration.AccessToken);
                }
                else if (!string.IsNullOrEmpty(this.Configuration.OAuthTokenUrl) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientId) &&
                         !string.IsNullOrEmpty(this.Configuration.OAuthClientSecret) &&
                         this.Configuration.OAuthFlow != null)
                {
                    localVarRequestOptions.OAuth = true;
                }
            }

            // make the HTTP request
            var localVarResponse = await this.AsynchronousClient.PostAsync<TranscriptionsCreate200Response>("/deployments/{deployment-id}/audio/translations", localVarRequestOptions, this.Configuration, cancellationToken).ConfigureAwait(false);

            if (this.ExceptionFactory != null)
            {
                Exception _exception = this.ExceptionFactory("TranslationsCreate", localVarResponse);
                if (_exception != null)
                {
                    throw _exception;
                }
            }

            return localVarResponse;
        }

    }
}
